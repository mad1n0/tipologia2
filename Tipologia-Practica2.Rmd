---
title: "Practica 2: Limpieza y análisis de datos"
author: "Autor: Marc Valdivieso Merino y Samuel Campo Martínez"
date: "Junio 2020"
output:
  html_document:
    highlight: default
    toc: yes
    toc_depth: 4
    code_folding: hide
    fig.show: hide
    number_sections: yes
    theme: cosmo
  pdf_document: default
---

```{r setup, include=FALSE,echo=FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("psych",repos = "http://cran.us.r-project.org")
#install.packages("rlang",repos = "http://cran.us.r-project.org")
#install.packages("VIM",repos = "http://cran.us.r-project.org")
#install.packages("pROC",repos = "http://cran.us.r-project.org")
#install.packages("ResourceSelection",repos = "http://cran.us.r-project.org")
#install.packages("scales",repos = "http://cran.us.r-project.org")
#install.packages("gmodels",repos = "http://cran.us.r-project.org")
#install.packages("faraway",repos = "http://cran.us.r-project.org")
#list.of.packages <- c("VIM")
#new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
#if(length(new.packages)) install.packages(new.packages)
```

````{r, echo=FALSE,message=FALSE,warning=FALSE}
#Cargamos las librerías psych, stringr y VIM para la media de winsorizada, para hacer labores complejas con strings y VIM para transformar los valores perdidos usando el método kNN
#library(psych)
#library(stringr)
library(VIM)
library(knitr)
library(pROC)
library(questionr)
library(scales)
library(ResourceSelection)
library(gmodels)
library(faraway)
library(car)
library(rattle)
library(rpart)
library(mltools)
````

# Carga y descripción del dataset elegido.

````{r}
raw_data<-read.csv("energy_dataset.csv",stringsAsFactors = FALSE)
summary(raw_data)
````

## Resumen cuantitativo del *dataset* escogido:




````{r}
tab_stats_descr<-data.frame()

tab_stats_data

for (feature in names(tab_stats_data)){
  aux_box_feature<-boxplot.stats(tab_stats_data[,feature])
  tab_stats_descr[,"Median"]<-aux_box_feature[3]
  tab_stats_descr[,"Max"]<-aux_box_feature[6]
  tab_stats_descr[,"Min"]<-aux_box_feature[1]
  tab_stats_descr[,"1st Quantile"]<-aux_box_feature[2]
  tab_stats_descr[,"3rd Quantile"]<-aux_box_feature[5]
  tab_stats_descr[,"Count NAs"]<-aux_box_feature[7]
}



````







## Descripción de las variables y su contenido

El dataset elegido es el energy_dataset de Kaggle (1). Contiene datos sobre la producción energética dee cada uno de los tipos de energía listados en las columnas y el coste de la compra de energía en cada uno de los instantes en los que se captura la información del dataset, durante un plazo de tiempo de tres años. Con él tenemos la intención de identificar qué factores y en qué medida la generación no controlable de energía renovable y la necesidad de consumo energético, así como la demanda energética, conducen a una fluctuación del precio de la energía, en qué momentos y estaciones. El dataset cuenta con los siguientes campos:

- **Time**: Variable timestamp, actualizada cada hora. entre 1 de enero de 2015 y 2019. Incluye fecha y hora, tipo char.

- **generation.biomass**: Cantidad de energía por biomasa generada. Valor numérico.

- **generation.fossil.brown.coal.ignite**: Cantidad de energía por quema de carbón marrón generada. Valor numérico.

- **generation.fossil.coal.derived.gas**: Cantidad de energía por derivados de carbón generada. Valor numérico.

- **generation.fossil.gas**: Cantidad de energía por gas generada. Valor numérico.

- **generation.fossil.hard.coal**: Cantidad de energía por carbón duro generada. Valor numérico.

- **generation.fossil.oil**: Cantidad de energía por petróleo generada. Valor numérico.

- **generation.fossil.oil.shale**: Cantidad de energía por petróleo bituminoso generada. Valor numérico. No hay valores disponibles ene l datasest.

- **generation.fossil.peat**: Cantidad de energía por petróleo vegetal generada. Valor numérico.

- **generation.geothermal**: Cantidad de energía geotérmica capturada. Valor numérico.

- **generation.hydro.pumped.storage.aggregated**: Cantidad de energía hidráulica acumulada. Valor numérico. No hay valores disponibles de este campo, son NA.

- **generation.hydro.pumped.storage.consumption**: Cantidad de energía hidráulica generada a través de consumir reservas de ésta (en una presa o parecidos). Valor numérico.

- **generation.hydro.run.of.river.and.poundage**: Cantidad de energía hidráulica en río capturada. Valor numérico.

- **generation.hydro.water.reservoir**: Cantidad de energía hidráulica en río en reservas. Valor numérico.

- **generation.marine**: Cantidad de energía hidráulica marina capturada. Valor numérico. Sin valores disponibles.

- **generation.nuclear**: Cantidad de energía nuclear generada. Valor numérico.

- **generation.other**: Cantidad de energía por biomasa generada. Valor numérico.

- **generation.other.renewable**: Cantidad de energía conseguida por otros métodos. Valor numérico.

- **generation.solar**: Cantidad de energía solar generada. Valor numérico.

- **generation.waste**: Cantidad de energía por quema de restos. Valor numérico.

- **generation.wind.offshore**: Cantidad de energía eólica capturada fuera de la frontera de España. Valor numérico.

- **generation.wind.onshore**: Cantidad de energía eólica capturada dentro de la frontera de España. Valor numérico.

- **forecast.solar.day.ahead**: Cantidad de energía solar prevista al día siguiente. Valor numérico.

- **forecast.wind.offshore.eday.ahead**: Cantidad de energía eólica prevista para el día siguiente fuera de la frontera. Valor numérico.

- **forecast.wind.onshore.day.ahead**: Cantidad de energía eólica prevista para el día siguiente dentro de la frontera. Valor numérico.

- **total.load.forecast**: Previsión de la cantidad de energía requerida al siguiente día. Valor numérico. 

- **total.load.actual**: Cantidad de energía requerida en el momento actual. Valor numérico.

- **price.day.ahead**: Precio de la energía en el caso de hacer una compra anticipada para el día siguiente.

- **price.actual**: Precio de la energía en el momento de la captura de los datos.


Unas de las preguntas que intentaremos resolver son:<br></br>
- **¿Cuál es el precio de la electricidad según su origen?**<br></br>
- **¿Hay fuentes de energías que estadísticamente encarecen el precio final?**<br></br>


# Selección de datos de interés.

## Desechar variables constantes
Podemos ver en el summary anterior que hay una serie de variables que solo contienen cero y elementos vacíos.

````{r}
lack_info_names<-c()
for (lack_info in names(raw_data)){
  if ((length(unique(raw_data[,lack_info]))<=2)){
    lack_info_names<-append(lack_info_names,lack_info)
  }
}

````

Estos son dichas variables: `r as.character(lack_info_names)` <br></br>

Ese valor nulo, sin ninguna variación en todos los registros, puede demostrar dos cosas: falta de datos sobre la variable o que realmente se trata de un valor nulo constante. Sea como fuere, una variable constante no genera ninguna dependencia o patrón del que extraer información, más allá de con las otras variables que también puedan ser constantes.<br></br>


## Discretización de la serie temporal

Como no vamos a hacer una evaluación de una serie temporal lo que hacemos es discretizar la variable Time creando dos variables nuevas: daytime y season, para identificar el registro en el momento del día y la estación del año. Estas dos variables conforman 4 columnas con valores numéricos en una y caracteres en la otra.
````{r}
date_data<-as.POSIXlt(raw_data$time)
day_cond<-(date_data$hour>6) & (date_data$hour<=12)
afternoon_cond<-(date_data$hour>12) & (date_data$hour<=18)
evening_cond<-(date_data$hour>18) & (date_data$hour<=23)
night_cond<-(date_data$hour>=0) & (date_data$hour<=6)

spring_cond<-(date_data$mon>=3) & (date_data$mon<6)
summer_cond<-(date_data$mon>=6) & (date_data$mon<9)
fall_cond<-(date_data$mon>=9) & (date_data$mon<12)
winter_cond<-(date_data$mon>=12) | (date_data$mon<3)

raw_data[day_cond,"daytime_dis"]<-1
raw_data[afternoon_cond,"daytime_dis"]<-2
raw_data[evening_cond,"daytime_dis"]<-3
raw_data[night_cond,"daytime_dis"]<-4

raw_data[spring_cond,"season_dis"]<-1
raw_data[summer_cond,"season_dis"]<-2
raw_data[fall_cond,"season_dis"]<-3
raw_data[winter_cond,"season_dis"]<-4

raw_data[day_cond,"daytime"]<-"day"
raw_data[afternoon_cond,"daytime"]<-"afternoon"
raw_data[evening_cond,"daytime"]<-"evening"
raw_data[night_cond,"daytime"]<-"night"

raw_data[spring_cond,"season"]<-"spring"
raw_data[summer_cond,"season"]<-"summer"
raw_data[fall_cond,"season"]<-"fall"
raw_data[winter_cond,"season"]<-"winter"

set.seed(42)

treat_data<-raw_data[-1]

treat_data<-treat_data[sample(nrow(treat_data)),]
rownames(treat_data)<-NULL
````

La distribución de las horas y los meses para crear esas variables discretizantes es:

- **daytime**<br></br> 
  - Day: de 7h a 12h<br></br> 
  - Afternoon: de 13h a 18h<br></br> 
  - Evening: de 19h a 23h<br></br> 
  - Night: desde medianoche hasta las 6h de la mañana del día siguiente.<br></br> 

- **season:**<br></br> 
  - Spring: de Marzo a Mayo incluido.<br></br>
  - Summer: de Junio a Agosto incluido.<br></br>
  - Fall: de Septiembre a Noviembre incluido.<br></br>
  - Winter: de Diciembre a Febrero incluido.<br></br>



````{r}
treat_data<-subset(treat_data,select = -c(generation.hydro.pumped.storage.aggregated,forecast.wind.offshore.eday.ahead,generation.geothermal,generation.marine,generation.fossil.peat,generation.fossil.oil.shale,generation.fossil.coal.derived.gas,generation.wind.offshore))
````


# Limpieza de datos

Tras haber seleccionado las columnas que vamos a emplear seguimos con una limpieza por variables de valores *outliers*, valores vacíos y errores que podamos encontrar.


## Valores outliers

````{r}
clean_data<-treat_data

aux_data<-clean_data[,1:(length(clean_data)-2)] #Cogemos solamente los valores numéricos quitando las columnas de las variables categóricas del daytime y la season.
````
````{r fig.width=4, fig.height=6,echo=FALSE,out.extra='style="float:left"'}
for (feature in names(aux_data)){
  aux_out<-boxplot.stats(aux_data[,feature])$out
  if (length(aux_out)>0){
    boxplot(aux_data[,feature],main=feature,cex.main=0.85)
    hist(aux_data[,feature],main=feature,100,xlab = feature,cex.main=0.85)
  }
}
````

````{r}
list_outliers_features<-c("generation.biomass","generation.fossil.gas","generation.fossil.oil","generation.nuclear","generation.other.renewable")

clean_data[clean_data[,"generation.biomass"]<150 & !(is.na(clean_data[,"generation.biomass"])),"generation.biomass"]<-NA
clean_data[clean_data[,"generation.fossil.gas"]>=15000 & !(is.na(clean_data[,"generation.fossil.gas"])),"generation.fossil.gas"]<-NA
clean_data[clean_data[,"generation.fossil.oil"]<150 & !(is.na(clean_data[,"generation.fossil.oil"])),"generation.fossil.oil"]<-NA
clean_data[clean_data[,"generation.nuclear"]<3500 & !(is.na(clean_data[,"generation.nuclear"])),"generation.nuclear"]<-NA
clean_data[clean_data[,"generation.other.renewable"]<50 & !(is.na(clean_data[,"generation.other.renewable"])),"generation.other.renewable"]<-NA

````

Hemos hecho un análisis de esas gráficas y vemos que solamente en las siguientes **_features_ tenemos outliers que deben ser reparados:** <br></br>
- **generation.biomass**<br></br>
- **generation.fossil.gas**<br></br>
- **generation.fossil.oil**<br></br>
- **generation.nuclear**<br></br>
- **generation.other.renewable**<br></br>

El resto se tratan de distribuciones normales multimodales, con ciertas anomalías interesantes, o distribuciones con una evolución exponencial de la frecuencia según el valor de la variable.<br></br>

En el caso de las distribuciones multimodales tenemos la *feature* **generation.other** que quizá se podría dividir en 3 grupos de generación. De igual tenemos el ejemplo de bimodalidad en **generation.other.renewable**<br></br>

Las anomalías interesantes las vemos en **generation.nuclear** o **generation.waste**. En la primera podríamos ver una mayor producción de energía nuclear, quizá porque hubiera una disminución de producción en el resto por falta de carbón, viento o sol. En la segunda vemos unos tímidos picos en lo que parece una distribución asimétrica, quizá por mayor cantidad de desecho disponible. Ambos ejemplos nos lleva a pensar: ¿existe una relación entre las diferentes fuentes de generación de energía? ¿Podemos ver cuándo ocurren esas "anomalías interesantes" y entender si se trata de mayor disposición del material para la generación: carbón, viento, luz solar, desechos, etc.?<br></br>

Por último tenemos distribuciones extremas como **generation.fossil.gas** o **generation.hydro.pumped.storage.consumption**. En la primera *feature* la dispersión es pequeña y por tanto algunos valores quedan fuera de los quantiles formando parte de los *outliers*. En el otro caso tenemos que hay muchos días que no se genera energía con la técnica de agua  

## Valores NA

Vamos a imputar valores a los NA que tenía el *dataset* de base y a los outliers que hemos considerado para cambiarlos a NA. De primeras nos gustaría mostrar el siguiente histograma sobre cómo se distribuye los valores de generación de energía nuclear.

````{r}
hist(aux_data[,"generation.nuclear"],main="generation.nuclear",100)
````

Para imputar nuevos valores vamos a calcularlos usando un modelo predictivo con el algormitmo kNN que nos dará el valor esperado según los registros más similares a este según las otras features. Esa similitud se calcula en base de la distancia euclidiana entre registros y al usarse el valor numérico de cada variable necesitamos que todas estén en un dominio numérico similar, con lo que hacemos un proceso de normalización de las variables numéricas.

````{r}
aux_data<-clean_data[,1:(length(clean_data)-2)] #Cogemos solamente los valores numéricos quitando las columnas de las variables categóricas del daytime y la season.

for (feature in names(aux_data)){
    aux_data[!(is.na(aux_data[,feature])),feature]<-scale(aux_data[!(is.na(aux_data[,feature])),feature])
}
````

Tras este proceso de normalización vemos cómo los valores cambian y visualmente la distribución puede tener diferencias. Pero matemáticamente no tendríamos que tener una pérdida de información en nuestros datos.

````{r}
hist(aux_data[,"generation.nuclear"],main="generation.nuclear",100)
````

Estando el conjunto de datos en la misma escala, pasamos finalmente a imputar valores a los registros NA.

````{r}
for (feature in names(aux_data)){
  if ((any(is.na(aux_data[,feature])))){
    #aux_data[!(is.na(aux_data[,feature])),feature]<-scale(aux_data[!(is.na(aux_data[,feature])),feature])
    aux_data[,feature]<-kNN(aux_data,k=30)[,feature]
  }
}

scl_clean_data<-aux_data
scl_clean_data[,"season"]<-clean_data[,"season"]
scl_clean_data[,"daytime"]<-clean_data[,"daytime"]
````


## Sumario del dataset preprocesado

````{r}
summary(scl_clean_data)
````

- Time
- generation.fossil.brown.coal.ignite
- generation.fossil.gas
- generation.fossil.hard.coal
- generation.fossil.oil
- generation.hydro.pumped.storage.consumption
- generation.hydro.run.of.river.and.poundage
- generation.hydro.water.reservoir
- generation.nuclear
- generation.other
- generation.other.renewable
- generation.solar
- generation.waste
- generation.wind.onshore
- total.load.forecast
- total.load.actual
- price.day.ahead
- price.actual
- daytime_dis
- season_dis
- daytime
- season

# Análisis

## Decisión de los datos a comparar

## Análisis de varianza del dataset

````{r include=FALSE,echo=FALSE,message=FALSE,warning=FALSE}
for (i in names(aux_data)){hist(aux_data[,i],100,main = i)}
````


Se hace una regresión lineal del precio para ver la evolución de los residuos y estudiar la homocedasticidad. Cuando los residuos no vayan aumentando con precios mayores, tendremos una varianza constante y por lo tanto nuestro *dataset* cumplirá la propiedad de homocedasticidad.
````{r}
lm_price<-lm(price.actual ~ . ,data = aux_data)
rsquarelm<-summary(lm_price)$adj.r.squared

aux_data_res_lm_price<-data.frame(prices=aux_data$price.actual,residuals=summary(lm_price)$residual)
aux_res_lm_price<-lm(residuals ~ prices ,data = aux_data_res_lm_price)
aux_res_lm_price_x_data<-data.frame(prices=seq(-5,5,0.05))
aux_res_lm_price_y_data<-predict(aux_res_lm_price,newdata=aux_res_lm_price_x_data)

plot(aux_data_res_lm_price$prices,aux_data_res_lm_price$residuals,xlab="Precios",ylab="Residuos")
lines(aux_res_lm_price_x_data$prices,aux_res_lm_price_y_data,col="red",lwd=4)
lines(c(-4,4),c(-3,3),col="blue",lwd=4)
legend(-3, legend=c("Regresión de los valores de los residuos","Línea imaginaria"), col=c("red","blue"), lty=1:2)
````

Como prueba visual sobre dicha línea imaginaria se debe cumplir equidistancia entre los residuos por abajo y por arriba para que se cumpla la propiedad de homocedasticidad.

¿POR QUÉ EXISTE ESA SEGUNDA LINEA ALREDEDOR DEL VALOR NULO DE LOS RESIDUOS? ¿CUALES SON LOS ""TIPOS"" DE REGISTROS QUE MEJOR REGRESIONA?


## Análisis predictivo 

Por otro lado vamos a intentar ver si podemos hacer un modelo de regresión con un arbol de decisión cuyo *complexity parameter* (N) sea muy bajo para que el acierto en las poblaciones sea mayor. Para hacer la evaluación del modelo partido los datos en un set para entrenamiento y otro para testeo.

````{r}
x_train<-aux_data[1:(nrow(aux_data)*0.7),]
x_test<-aux_data[(nrow(aux_data)*0.7):nrow(aux_data),]
````

### Entrenamiento

Entrenaremos el modelo ajustando los parámetros para que sea preciso. En la evaluación podremos ver si estamos sobreentrenando o si el modelo es suficientemente bueno.
````{r}
tree_model<-rpart(price.actual ~ ., data=x_train,control=rpart.control(minsplit=2, minbucket = 1,cp=0.00001))

nodes <- as.numeric(rownames(tree_model$frame))

max_depth_tree_model<-max(rpart:::tree.depth(nodes))

````

Aquí tenemos una parte del modelo, hemos hecho *pruning* porque el árbol original tiene (N+1) ramas con una profundidad máxima de `r max_depth_tree_model` y `r length(tree_model$splits)` particiones; con lo que queda claro el motivo por el que recortar el árbol a mostrar.

````{r}
brief_tree_model<-prune.rpart(tree_model,cp=0.01)

fancyRpartPlot(brief_tree_model,caption="Extracto de la totalidad del árbol")
````


### Evaluación del modelo

Ahora hacemos la predicción del precio con el modelo y el conjunto de datos de test.
````{r}
prices_pred<-predict(tree_model,newdata=x_test)
prices_real<-x_test$price.actual
````

Teniendo los valores esperados y reales podemos calcular una de las métricas que identifica la calidad del modelo, el **root mean square error**.

````{r}
rmse_tree_model<-rmse(preds = prices_pred,actuals = prices_real)
````

Podemos ver que el modelo tiene un **root mean square error** de: `r round(rmse_tree_model,3)`, teniendo en cuenta que los valores escalados van entre `r min(x_train$price.actual)` y `r max(x_train$price.actual)` ese valor medio del error no parece demasiado para un módelo con una configuración tan simple.

### Feature importance

Más allá de la calidad del árbol podemos ver las variables más importantes a la hora de hacer la regresión. Esta importancia se estima por la cantidad de divisiones que se han hecho teniendo en cuenta esa variable. Dado que el algoritmo tiene en cuenta la variable y la condición para la que se puede tener una mayor minimización de la entropía, se entiende que la variable elegida es más relevante que el resto. Por ello las variables con mayor frecuencia de uso en las divisiones se les considera como las más importantes en todo el árbol.

````{r}
sum_nodes_tree<-sum(tree_model$variable.importance)
feature_importance_tree_model_percentage<-(100*tree_model$variable.importance/sum_nodes_tree)

kable(feature_importance_tree_model_percentage)
````





# Referencias
(1) https://www.kaggle.com/nicholasjhana/energy-consumption-generation-prices-and-weather?select=weather_features.csv
(2) https://data.library.virginia.edu/understanding-q-q-plots/
(3) https://es.wikipedia.org/wiki/Propagaci%C3%B3n_de_errores
(4) http://pages.stat.wisc.edu/~st571-1/06-tables-4.pdf
(5) http://networkianos.com/odd-ratio-que-es-como-se-interpreta/#toc-3 
(6) https://prevencion.umh.es/files/2015/03/riesgo-relativo-y-odds-ratio.pdf
(7) https://stats.stackexchange.com/questions/25839/logistic-regression-in-r-returning-na-values
(8) https://en.wikipedia.org/wiki/Hosmer%E2%80%93Lemeshow_test 
(9) https://www.statisticshowto.com/hosmer-lemeshow-test/ 
(N) http://www.learnbymarketing.com/tutorials/rpart-decision-trees-in-r/ 
(N+1) https://stackoverflow.com/questions/40897081/how-can-i-get-the-depth-of-the-tree-in-rpart-model