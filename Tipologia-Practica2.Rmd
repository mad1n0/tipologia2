---
title: "Practica 2: Limpieza y análisis de datos"
author: "Autor: Marc Valdivieso Merino y Samuel Campo Martínez"
date: "Junio 2020"
output:
  html_document:
    highlight: default
    toc: yes
    toc_depth: 4
    code_folding: hide
    fig.show: hide
    number_sections: yes
    theme: cosmo
  pdf_document: default
---

```{r setup, include=FALSE,echo=FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("psych",repos = "http://cran.us.r-project.org")
#install.packages("rlang",repos = "http://cran.us.r-project.org")
#install.packages("VIM",repos = "http://cran.us.r-project.org")
#install.packages("pROC",repos = "http://cran.us.r-project.org")
#install.packages("ResourceSelection",repos = "http://cran.us.r-project.org")
#install.packages("scales",repos = "http://cran.us.r-project.org")
#install.packages("gmodels",repos = "http://cran.us.r-project.org")
#install.packages("faraway",repos = "http://cran.us.r-project.org")
#install.packages("nortest",repos = "http://cran.us.r-project.org")
#install.packages("DescTools",repos = "http://cran.us.r-project.org")
#list.of.packages <- c("VIM")
#new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
#if(length(new.packages)) install.packages(new.packages)
```

````{r, echo=FALSE,message=FALSE,warning=FALSE}
#Cargamos las librerías psych, stringr y VIM para la media de winsorizada, para hacer labores complejas con strings y VIM para transformar los valores perdidos usando el método kNN
#library(psych)
#library(stringr)
library(VIM)
library(knitr)
library(pROC)
library(questionr)
library(scales)
library(ResourceSelection)
library(gmodels)
library(faraway)
library(car)
library(rattle)
library(rpart)
library(mltools)
library(nortest)
library(DescTools)
````

# Carga y descripción del dataset elegido.

````{r}
raw_data<-read.csv("energy_dataset.csv",stringsAsFactors = FALSE)
#summary(raw_data)
````

## Resumen cuantitativo del *dataset* escogido:


Las variables numéricas tienen las siguientes características:

````{r}
#Hemos usado una representación propia ya que la función summary generaba demasiado texto

tab_stats_data<-data.frame(c(vector(),1:nrow(raw_data)))

for (feature in names(raw_data)){
  if (class(raw_data[,feature])=="numeric"){
    tab_stats_data[,feature]<-raw_data[,feature]
  }
}
tab_stats_data<-tab_stats_data[,-1]

tab_stats_descr<-data.frame(c(vector(),1:length(names(tab_stats_data))))
rownames(tab_stats_descr)<-names(tab_stats_data)

#tab_stats_data
i<-1
for (feature in names(tab_stats_data)){
  aux_box_feature<-boxplot.stats(tab_stats_data[,feature])$stats
  tab_stats_descr[i,"Median"]<-aux_box_feature[3]
  tab_stats_descr[i,"Median absolute deviation"]<-mad(tab_stats_data[,feature],na.rm=T)
  tab_stats_descr[i,"Max"]<-max(tab_stats_data[,feature],na.rm=T)
  tab_stats_descr[i,"Min"]<-min(tab_stats_data[,feature],na.rm=T)
  tab_stats_descr[i,"1st Quantile"]<-aux_box_feature[1]
  tab_stats_descr[i,"3rd Quantile"]<-aux_box_feature[4]
  tab_stats_descr[i,"Count NAs"]<-length((tab_stats_data[is.na(tab_stats_data[,feature]),feature]))
  i<-i+1
}

tab_stats_descr<-round(tab_stats_descr[,-1],1)
````

<p>
  <a class="btn btn-primary" data-toggle="collapse" href="#statsfeatures" role="button" aria-expanded="false" aria-controls="statsfeatures">
    Tabla de características estadísticas de las variables
  </a>
</p>
<div class="collapse" id="statsfeatures">
  <div class="card card-body">
  
````{r}
kable(tab_stats_descr)
````

  </div>
</div>


Además de las variables numéricas tenemos algunas como es la fecha u aquellas que solo contienen NAs
````{r}
summ_stats_data<-data.frame(c(vector(),1:nrow(raw_data)))


for (feature in names(raw_data)){
  if (class(raw_data[,feature])!="numeric"){
    summ_stats_data[,feature]<-raw_data[,feature]
  }
}
summ_stats_data<-summ_stats_data[,-1]

summary(summ_stats_data)
````




## Descripción de las variables y su contenido

El dataset elegido es el energy_dataset de Kaggle (1). Contiene datos sobre la producción energética dee cada uno de los tipos de energía listados en las columnas y el coste de la compra de energía en cada uno de los instantes en los que se captura la información del dataset, durante un plazo de tiempo de tres años. Con él tenemos la intención de identificar qué factores y en qué medida la generación no controlable de energía renovable y la necesidad de consumo energético, así como la demanda energética, conducen a una fluctuación del precio de la energía, en qué momentos y estaciones. El dataset cuenta con los siguientes campos:

<p>
  <a class="btn btn-primary" data-toggle="collapse" href="#descriptionfeatures" role="button" aria-expanded="false" aria-controls="descriptionfeatures">
    Descripción de todas las variables
  </a>
</p>
<div class="collapse" id="descriptionfeatures">
  <div class="card card-body">

- **Time**: Variable timestamp, actualizada cada hora. entre 1 de enero de 2015 y 2019. Incluye fecha y hora, tipo char.

- **generation.biomass**: Cantidad de energía por biomasa generada. Valor numérico.

- **generation.fossil.brown.coal.ignite**: Cantidad de energía por quema de carbón marrón generada. Valor numérico.

- **generation.fossil.coal.derived.gas**: Cantidad de energía por derivados de carbón generada. Valor numérico.

- **generation.fossil.gas**: Cantidad de energía por gas generada. Valor numérico.

- **generation.fossil.hard.coal**: Cantidad de energía por carbón duro generada. Valor numérico.

- **generation.fossil.oil**: Cantidad de energía por petróleo generada. Valor numérico.

- **generation.fossil.oil.shale**: Cantidad de energía por petróleo bituminoso generada. Valor numérico. No hay valores disponibles ene l datasest.

- **generation.fossil.peat**: Cantidad de energía por petróleo vegetal generada. Valor numérico.

- **generation.geothermal**: Cantidad de energía geotérmica capturada. Valor numérico.

- **generation.hydro.pumped.storage.aggregated**: Cantidad de energía hidráulica acumulada. Valor numérico. No hay valores disponibles de este campo, son NA.

- **generation.hydro.pumped.storage.consumption**: Cantidad de energía hidráulica generada a través de consumir reservas de ésta (en una presa o parecidos). Valor numérico.

- **generation.hydro.run.of.river.and.poundage**: Cantidad de energía hidráulica en río capturada. Valor numérico.

- **generation.hydro.water.reservoir**: Cantidad de energía hidráulica en río en reservas. Valor numérico.

- **generation.marine**: Cantidad de energía hidráulica marina capturada. Valor numérico. Sin valores disponibles.

- **generation.nuclear**: Cantidad de energía nuclear generada. Valor numérico.

- **generation.other**: Cantidad de energía por biomasa generada. Valor numérico.

- **generation.other.renewable**: Cantidad de energía conseguida por otros métodos. Valor numérico.

- **generation.solar**: Cantidad de energía solar generada. Valor numérico.

- **generation.waste**: Cantidad de energía por quema de restos. Valor numérico.

- **generation.wind.offshore**: Cantidad de energía eólica capturada fuera de la frontera de España. Valor numérico.

- **generation.wind.onshore**: Cantidad de energía eólica capturada dentro de la frontera de España. Valor numérico.

- **forecast.solar.day.ahead**: Cantidad de energía solar prevista al día siguiente. Valor numérico.

- **forecast.wind.offshore.eday.ahead**: Cantidad de energía eólica prevista para el día siguiente fuera de la frontera. Valor numérico.

- **forecast.wind.onshore.day.ahead**: Cantidad de energía eólica prevista para el día siguiente dentro de la frontera. Valor numérico.

- **total.load.forecast**: Previsión de la cantidad de energía requerida al siguiente día. Valor numérico. 

- **total.load.actual**: Cantidad de energía requerida en el momento actual. Valor numérico.

- **price.day.ahead**: Precio de la energía en el caso de hacer una compra anticipada para el día siguiente.

- **price.actual**: Precio de la energía en el momento de la captura de los datos.


  </div>
</div>


Unas de las preguntas que intentaremos resolver son:<br></br>
- **¿Cuál es el precio de la electricidad sabiendo la generación y su origen?**<br></br>
- **¿Hay fuentes de energías que estadísticamente encarecen el precio final?**<br></br>


# Selección de datos de interés.

## Desechar variables constantes
Podemos ver en el summary anterior que hay una serie de variables que solo contienen cero y elementos vacíos.

````{r}
lack_info_names<-c()
for (lack_info in names(raw_data)){
  if ((length(unique(raw_data[,lack_info]))<=2)){
    lack_info_names<-append(lack_info_names,lack_info)
  }
}

````

Estos son dichas variables: `r as.character(lack_info_names)` <br></br>

Ese valor nulo, sin ninguna variación en todos los registros, puede demostrar dos cosas: falta de datos sobre la variable o que realmente se trata de un valor nulo constante. Sea como fuere, una variable constante no genera ninguna dependencia o patrón del que extraer información, más allá de con las otras variables que también puedan ser constantes.<br></br>


## Discretización de la serie temporal

Como no vamos a hacer una evaluación de una serie temporal lo que hacemos es discretizar la variable Time creando dos variables nuevas: daytime y season, para identificar el registro en el momento del día y la estación del año. Estas dos variables conforman 4 columnas con valores numéricos en una y caracteres en la otra.
````{r}
date_data<-as.POSIXlt(raw_data$time)
day_cond<-(date_data$hour>6) & (date_data$hour<=12)
afternoon_cond<-(date_data$hour>12) & (date_data$hour<=18)
evening_cond<-(date_data$hour>18) & (date_data$hour<=23)
night_cond<-(date_data$hour>=0) & (date_data$hour<=6)

spring_cond<-(date_data$mon>=3) & (date_data$mon<6)
summer_cond<-(date_data$mon>=6) & (date_data$mon<9)
fall_cond<-(date_data$mon>=9) & (date_data$mon<12)
winter_cond<-(date_data$mon>=12) | (date_data$mon<3)

raw_data[day_cond,"daytime_dis"]<-1
raw_data[afternoon_cond,"daytime_dis"]<-2
raw_data[evening_cond,"daytime_dis"]<-3
raw_data[night_cond,"daytime_dis"]<-4

raw_data[spring_cond,"season_dis"]<-1
raw_data[summer_cond,"season_dis"]<-2
raw_data[fall_cond,"season_dis"]<-3
raw_data[winter_cond,"season_dis"]<-4

raw_data[day_cond,"daytime"]<-"day"
raw_data[afternoon_cond,"daytime"]<-"afternoon"
raw_data[evening_cond,"daytime"]<-"evening"
raw_data[night_cond,"daytime"]<-"night"

raw_data[spring_cond,"season"]<-"spring"
raw_data[summer_cond,"season"]<-"summer"
raw_data[fall_cond,"season"]<-"fall"
raw_data[winter_cond,"season"]<-"winter"

set.seed(42)

treat_data<-raw_data[-1]

treat_data<-treat_data[sample(nrow(treat_data)),]
rownames(treat_data)<-NULL
````

La distribución de las horas y los meses para crear esas variables discretizantes es:

- **daytime**<br></br> 
  - Day: de 7h a 12h<br></br> 
  - Afternoon: de 13h a 18h<br></br> 
  - Evening: de 19h a 23h<br></br> 
  - Night: desde medianoche hasta las 6h de la mañana del día siguiente.<br></br> 

- **season:**<br></br> 
  - Spring: de Marzo a Mayo incluido.<br></br>
  - Summer: de Junio a Agosto incluido.<br></br>
  - Fall: de Septiembre a Noviembre incluido.<br></br>
  - Winter: de Diciembre a Febrero incluido.<br></br>



````{r}
treat_data<-subset(treat_data,select = -c(generation.hydro.pumped.storage.aggregated,forecast.wind.offshore.eday.ahead,generation.geothermal,generation.marine,generation.fossil.peat,generation.fossil.oil.shale,generation.fossil.coal.derived.gas,generation.wind.offshore))
````


# Limpieza de datos

Tras haber seleccionado las columnas que vamos a emplear seguimos con una limpieza por variables de valores *outliers*, valores vacíos y errores que podamos encontrar.


## Valores outliers

En esta sección vamos a analizar los valores outliers representando su distribución junto a su boxplot. Con ello concluiremos cuales son relevantes y deben dejarse y cuales tendrían que ser tratados.
````{r}
clean_data<-treat_data

aux_data<-clean_data[,1:(length(clean_data)-2)] #Cogemos solamente los valores numéricos quitando las columnas de las variables categóricas del daytime y la season.
````

### Gráficas
<p>
  <a class="btn btn-primary" data-toggle="collapse" href="#outliersplots" role="button" aria-expanded="false" aria-controls="outliersplots">
    Gráficas de las variables con outliers
  </a>
</p>
<div class="collapse" id="outliersplots">
  <div class="card card-body">
````{r fig.width=4, fig.height=4,out.extra='style="float:center;padding:-60px -15px -10px -60px;margin:-50px -20px -50px -20px"'}
for (feature in names(aux_data)){
  aux_out<-boxplot.stats(aux_data[,feature])$out
  if (length(aux_out)>0){
    boxplot(aux_data[,feature],main=feature,cex.main=0.8,yaxt="n",xaxt="n",cex.lab=0.8,line=0,frame=FALSE)
    #par(mar = c(1,1,1,1))
    hist(aux_data[,feature],main="",30,cex.lab=0.8,xlab="",ylab = "",xaxt="n",yaxt="n")
    #hist(aux_data[,feature],main=feature,100,xlab = feature,cex.main=0.85,cex.lab=0.7,cex.axis=0.7,xaxt="n")
    #M_aux<-max(aux_data[,feature],na.rm = T)
    #m_aux<-min(aux_data[,feature],na.rm = T)
    #axis(side=1, at=round(seq(m_aux,M_aux,(M_aux-m_aux)/30),2), labels=round(seq(m_aux,M_aux,(M_aux-m_aux)/30),2),cex.axis=0.7,las=3)

  }
}
````
  </div>
</div>


### Tratamiento de los outliers

Hemos hecho un análisis de esas gráficas y vemos que solamente en las siguientes **_features_ tenemos outliers que deben ser reparados:** <br></br>
- **generation.biomass**<br></br>
- **generation.fossil.gas**<br></br>
- **generation.fossil.oil**<br></br>
- **generation.nuclear**<br></br>
- **generation.other.renewable**<br></br>

````{r}
list_outliers_features<-c("generation.biomass","generation.fossil.gas","generation.fossil.oil","generation.nuclear","generation.other.renewable")

clean_data[clean_data[,"generation.biomass"]<150 & !(is.na(clean_data[,"generation.biomass"])),"generation.biomass"]<-NA
clean_data[clean_data[,"generation.fossil.gas"]>=15000 & !(is.na(clean_data[,"generation.fossil.gas"])),"generation.fossil.gas"]<-NA
clean_data[clean_data[,"generation.fossil.oil"]<150 & !(is.na(clean_data[,"generation.fossil.oil"])),"generation.fossil.oil"]<-NA
clean_data[clean_data[,"generation.nuclear"]<3500 & !(is.na(clean_data[,"generation.nuclear"])),"generation.nuclear"]<-NA
clean_data[clean_data[,"generation.other.renewable"]<50 & !(is.na(clean_data[,"generation.other.renewable"])),"generation.other.renewable"]<-NA

````


El resto se tratan de distribuciones normales multimodales, con ciertas anomalías interesantes, o distribuciones con una evolución exponencial de la frecuencia según el valor de la variable.<br></br>

En el caso de las distribuciones multimodales tenemos la *feature* **generation.other** que quizá se podría dividir en 3 grupos de generación. De igual tenemos el ejemplo de bimodalidad en **generation.other.renewable**<br></br>

Las anomalías interesantes las vemos en **generation.nuclear** o **generation.waste**. En la primera podríamos ver una mayor producción de energía nuclear, quizá porque hubiera una disminución de producción en el resto por falta de carbón, viento o sol. En la segunda vemos unos tímidos picos en lo que parece una distribución asimétrica, quizá por mayor cantidad de desecho disponible. Ambos ejemplos nos lleva a pensar: ¿existe una relación entre las diferentes fuentes de generación de energía? ¿Podemos ver cuándo ocurren esas "anomalías interesantes" y entender si se trata de mayor disposición del material para la generación: carbón, viento, luz solar, desechos, etc.?<br></br>

Por último tenemos distribuciones extremas como **generation.fossil.gas** o **generation.hydro.pumped.storage.consumption**. En la primera *feature* la dispersión es pequeña y por tanto algunos valores quedan fuera de los quantiles formando parte de los *outliers*. En el otro caso tenemos que hay muchos días que no se genera energía con la técnica de agua  

## Valores NA

Vamos a imputar valores a los NA que tenía el *dataset* de base y a los outliers que hemos considerado para cambiarlos a NA. De primeras nos gustaría mostrar el siguiente histograma sobre cómo se distribuye los valores de generación de energía nuclear.

````{r}
hist(aux_data[,"generation.nuclear"],main="generation.nuclear",100)
````

Para imputar nuevos valores vamos a calcularlos usando un modelo predictivo con el algormitmo kNN que nos dará el valor esperado según los registros más similares a este según las otras features. Esa similitud se calcula en base de la distancia euclidiana entre registros y al usarse el valor numérico de cada variable necesitamos que todas estén en un dominio numérico similar, con lo que hacemos un proceso de normalización de las variables numéricas.

````{r}
aux_data<-clean_data[,1:(length(clean_data)-2)] #Cogemos solamente los valores numéricos quitando las columnas de las variables categóricas del daytime y la season.

for (feature in names(aux_data)){
    aux_data[!(is.na(aux_data[,feature])),feature]<-scale(aux_data[!(is.na(aux_data[,feature])),feature])
}
````

Tras este proceso de normalización vemos cómo los valores cambian y visualmente la distribución puede tener diferencias. Pero matemáticamente no tendríamos que tener una pérdida de información en nuestros datos.

````{r}
hist(aux_data[,"generation.nuclear"],main="generation.nuclear",100)
````

Estando el conjunto de datos en la misma escala, pasamos finalmente a imputar valores a los registros NA.

````{r}
for (feature in names(aux_data)){
  if ((any(is.na(aux_data[,feature])))){
    #aux_data[!(is.na(aux_data[,feature])),feature]<-scale(aux_data[!(is.na(aux_data[,feature])),feature])
    aux_data[,feature]<-kNN(aux_data,k=30)[,feature]
  }
}

scl_clean_data<-aux_data
scl_clean_data[,"season"]<-clean_data[,"season"]
scl_clean_data[,"daytime"]<-clean_data[,"daytime"]
````


## Sumario del dataset preprocesado

````{r}
#summary(scl_clean_data)
````

- Time
- generation.fossil.brown.coal.ignite
- generation.fossil.gas
- generation.fossil.hard.coal
- generation.fossil.oil
- generation.hydro.pumped.storage.consumption
- generation.hydro.run.of.river.and.poundage
- generation.hydro.water.reservoir
- generation.nuclear
- generation.other
- generation.other.renewable
- generation.solar
- generation.waste
- generation.wind.onshore
- total.load.forecast
- total.load.actual
- price.day.ahead
- price.actual
- daytime_dis
- season_dis
- daytime
- season

# Análisis

## Decisión de los datos a comparar

## Análisis de varianza y la normalidad del dataset
Antes de entrar en el análisis predictivo, vamos a estudiar la normalidad y la homocedasticidad. Ya que se presuponen esas propiedades a las variables que se les vaya a aplicar pruebas por contraste de hipótesis paramétricas u otros análisis.

Tenemos que entender que la normalidad es una propiedad única de cada variable y la homocedasticidad ocurre sobre la regresión de una variable dependiente frente a una o varias variables explicativas. La homocedasticidad ocurre cuando la varianza es constante bajo variaciones de la variable dependiente. Por todo esto, buscaremos normalidad en todas las variables y buscaremos el conjunto de variables que cumplen homocedasticidad al regresionar el precio de la electricidad. Y es que nuestro objetivo es estudiar la evolución del precio intentando responder, por ejemplo: su relación con la fuente generadora de energía, si existe una que afecte más que el resto o si tiene alguna relación con la época del día o del año.


### Estudio de normalidad para todas las variables
Para este caso recordamos el teorema del límite central que en el caso de poblaciones suficientemente grandes podemos asumir normalidad (N+3) (N+4). Sin embargo con el fin de realizar dicho estudio, evaluaremos la normalidad de diferentes muestras de nuestra población. Aunque lo ideal quizá hubiera sido hacer un estudio de la normalidad asintótica local o general (N+5) (N+6).

Para dicho estudio lo que vamos a hacer es aplicar los tests de Anderson-Darling (N+2) y Shapiro-Wilk en varias muestras de la población total para cada una de las variables. Solo aquellas variables que cuya mediana de todos los p-value de los tests den por encima de 0.05 serán tomados como normales según dichos tests.

````{r}

p_values_adtest<-c()
p_values_shapiro<-c()
normal_features_list<-c()


for (i in names(aux_data)){
  p_values_adtest<-c()
  p_values_shapiro<-c()
  for (cv in seq(1,500,1)){
    local_norm_sample <- sample(aux_data[,i],55, replace = TRUE)
    p_value_adtest<-ad.test(local_norm_sample)$p.value
    p_value_shapiro<-shapiro.test(local_norm_sample)$p.value
    p_values_adtest<-append(p_values_adtest,p_value_adtest)
    p_values_shapiro<-append(p_values_shapiro,p_value_shapiro)
    if ((median(p_values_adtest)>0.05) & (median(p_values_shapiro)>0.05)){
      normal_features_list<-append(normal_features_list,i)
    }
    #print(median(p_values_adtest))
    #print(median(p_values_shapiro))
  }
}

normal_features_list_2<-c()

for (i in names(aux_data)){
  if (!(i %in% unique(normal_features_list))){
    p_values_adtest<-c()
    p_values_shapiro<-c()
    for (cv in seq(1,500,1)){
      local_norm_sample <- sample(aux_data[,i],55, replace = TRUE)
      p_value_adtest<-ad.test(local_norm_sample)$p.value
      p_value_shapiro<-shapiro.test(local_norm_sample)$p.value
      p_values_adtest<-append(p_values_adtest,p_value_adtest)
      p_values_shapiro<-append(p_values_shapiro,p_value_shapiro)
      if ((median(p_values_adtest)>0.05) & (median(p_values_shapiro)>0.05)){
        normal_features_list_2<-append(normal_features_list_2,i)
      }
      #print(median(p_values_adtest))
      #print(median(p_values_shapiro))
    }
  }
}

````


Estas son las variables que, según los tests de Anderson-Darling y Shapiro-Wilk, podemos decir que cumplen con normalidad estadísticamente: `r unique(normal_features_list)`



<p>
  <a class="btn btn-primary" data-toggle="collapse" href="#normal_dist_features" role="button" aria-expanded="false" aria-controls="normal_dist_features">
    Histogramas de las variables en las que encontramos normalidad según los tests
  </a>
</p>
<div class="collapse" id="normal_dist_features">
  <div class="card card-body">

````{r}

for (feature in unique(normal_features_list)){
  hist(aux_data[,feature],100,xlab="",main=feature)
}
````

  </div>
</div>



Posteriormente hemos aplicado la transformación Box-Cox a las variables que anteriormente no tenían la normalidad probada.


````{r}

normal_features_list_2<-c()
for (i in names(aux_data)){
  if (!(i %in% unique(normal_features_list))){
    p_values_adtest<-c()
    p_values_shapiro<-c()
    for (cv in seq(1,100,1)){
      local_norm_sample <- sample(aux_data[,i],100, replace = TRUE)
      x <- BoxCox(local_norm_sample, lambda = BoxCoxLambda(local_norm_sample))
      p_value_adtest<-ad.test(x)$p.value
      p_value_shapiro<-shapiro.test(x)$p.value
      p_values_adtest<-append(p_values_adtest,p_value_adtest)
      p_values_shapiro<-append(p_values_shapiro,p_value_shapiro)
    }
    if ((max(p_values_adtest)>0.05) & (max(p_values_shapiro)>0.05)){
      plot(density(x),xlab=i)
      #qqnorm(x, main="Distribución",xlab=i)
      #qqline(x,col=2,xlab=i)
      hist(aux_data[,i],xlab=i,100,main="La variable sin transformar")
      #hist(xlab=i,BoxCox(aux_data[,i], lambda = BoxCoxLambda(local_norm_sample)),100,main="La variable bajo transformación BoX-Cox")
      #hist(x,xlab=i,100,main="La muestra que testea")
      normal_features_list_2<-append(normal_features_list_2,i)
    }
    #print(median(p_values_adtest))
    #print(median(p_values_shapiro))
  }
}

#for (i in names(aux_data)){
#  if (!(i %in% unique(normal_features_list))){
 #   dsample <- aux_data[1:50,i]
  #  x <- BoxCox(dsample, lambda = BoxCoxLambda(dsample))
   # p_value_adtest<-shapiro.test(x)$p.value
    #if (p_value_adtest>0.05){
    #  print(p_value_adtest)
    #  print(i)
     # plot(density(x),xlab=i)
      #qqnorm(x, main="Distribución",xlab=i)
      #qqline(x,col=2,xlab=i)
      #hist(aux_data[,i],xlab=i,100,main="La variable sin transformar")
      #hist(xlab=i,BoxCox(aux_data[,i], lambda = BoxCoxLambda(dsample)),100,main="La variable bajo transformación BoX-Cox")
      #hist(x,xlab=i,100,main="La muestra que testea")
    #}
  #}
#}



````

El resultado es que `r length(normal_features_list_2)` variables también las podemos considerar normales: `r unique(normal_features_list_2)`

### Comprobación de homocedasticidad para la regresión sobre la variable dependiente: el precio

````{r include=FALSE,echo=FALSE,message=FALSE,warning=FALSE}
for (i in names(aux_data)){hist(aux_data[,i],100,main = i)}
````


Se hace una regresión lineal del precio para ver la evolución de los residuos y estudiar la homocedasticidad. Cuando los residuos no vayan aumentando con precios mayores, tendremos una varianza constante y por lo tanto nuestro *dataset* cumplirá la propiedad de homocedasticidad.
````{r}
lm_price<-lm(price.actual ~ . ,data = aux_data)
rsquarelm<-summary(lm_price)$adj.r.squared

aux_data_res_lm_price<-data.frame(prices=aux_data$price.actual,residuals=summary(lm_price)$residual)
aux_res_lm_price<-lm(residuals ~ prices ,data = aux_data_res_lm_price)
aux_res_lm_price_x_data<-data.frame(prices=seq(-5,5,0.05))
aux_res_lm_price_y_data<-predict(aux_res_lm_price,newdata=aux_res_lm_price_x_data)

plot(aux_data_res_lm_price$prices,aux_data_res_lm_price$residuals,xlab="Precios",ylab="Residuos")
lines(aux_res_lm_price_x_data$prices,aux_res_lm_price_y_data,col="red",lwd=4)
lines(c(-4,4),c(-3,3),col="blue",lwd=4)
legend(-3, legend=c("Regresión de los valores de los residuos","Línea imaginaria"), col=c("red","blue"), lty=1:2)
````

Como prueba visual sobre dicha línea imaginaria se debe cumplir equidistancia entre los residuos por abajo y por arriba para que se cumpla la propiedad de homocedasticidad. Podemos ver como existe una simetría sobre dicho eje imaginario dando pie a pensar en la existencia de homocedasticidad para la variable del precio con respecto al resto.

Sin embargo, y de forma estadística, veremos que parece que no se cumple al aplicar 

````{r}

homocedasticity_features<-c()
for (name_j in names(aux_data)){
  p_value_fligner<-fligner.test(aux_data[,"price.actual"],aux_data[,name_j])$p.value
  if (name_j!="price.actual"){
    if (p_value_fligner>0.05){
      form_aux<-as.formula(paste("price.actual","~",name_j))
      lm_price_aux_norm<-lm(form_aux,data=aux_data)
      aux_res_lm_price_x_data<-data.frame(prices=seq(-5,5,0.05))
      plot(aux_data$price.actual,summary(lm_price_aux_norm)$residual,xlab="Precios",ylab="Residuos")
      print(name_j)
      print(p_value_fligner)
      homocedasticity_features<-append(homocedasticity_features,name_j)
    }
  }
}

p_values_fligner<-c()


for (cv in seq(1,20,1)){
  local_norm_sample <- sample(aux_data,55, replace = TRUE)
  p_value_fligner<-fligner.test(local_norm_sample)$p.value
  p_values_fligner<-append(p_values_fligner,p_value_fligner)
}



````


### Conclusiones del análisis de homocedasticidad y de normalidad

Tenemos normalidad demostrada en las siguientes variables:

`r kable(unique(normal_features_list_2),col.names=c("Features"))`
`r kable(unique(normal_features_list),col.names=c("Features"))`

Además hemos visto que existe cierta homocedasticidad entre el precio actual y el conjunto completo del resto de las variables. Aunque en relación uno a uno, estas son las que cumplen homocedasticidad al regresionar el precio:

`r kable(unique(homocedasticity_features),col.names=c("Features"))`


## Correlación, regresión y pruebas por contraste de hipótesis paramétricas

Usando las features que hemos mostrado antes haremos un estudio sobre sus correlaciones, capacidad de regresión y responderemos algunas preguntas usando el método de las hipótesis.

````{r}
good_features<-c()
good_features<-append(good_features,normal_features_list_2)
good_features<-append(good_features,normal_features_list)
good_features<-append(good_features,homocedasticity_features)
an_stats_data<-data.frame()
an_stats_data<-data.frame(c(vector(),1:nrow(aux_data)))
for (feature in unique(good_features)){
  an_stats_data[,feature]<-aux_data[,feature]
}
an_stats_data<-an_stats_data[-1]
````

### Correlación

Para ilustrar las correlaciones entre las diferentes variables usaremos un mapa de calor:

````{r}
heatmap(cor(an_stats_data))
````

### ¿Podemos decir que las energías renovables o alternativas generan una electricidad más barata?

### ¿Hay fuentes de energías que estadísticamente encarecen el precio final?



## Análisis predictivo. ¿Cuál es el precio de la electricidad sabiendo la generación y su origen?

Por otro lado vamos a intentar ver si podemos hacer un modelo de regresión con un arbol de decisión cuyo *complexity parameter* (N) sea muy bajo para que el acierto en las poblaciones sea mayor. Para hacer la evaluación del modelo partido los datos en un set para entrenamiento y otro para testeo.

````{r}
x_train<-aux_data[1:(nrow(aux_data)*0.7),]
x_test<-aux_data[(nrow(aux_data)*0.7):nrow(aux_data),]
````

### Entrenamiento

Entrenaremos el modelo ajustando los parámetros para que sea preciso. En la evaluación podremos ver si estamos sobreentrenando o si el modelo es suficientemente bueno.
````{r}
tree_model<-rpart(price.actual ~ ., data=x_train,control=rpart.control(minsplit=2, minbucket = 1,cp=0.00001))

nodes <- as.numeric(rownames(tree_model$frame))

max_depth_tree_model<-max(rpart:::tree.depth(nodes))

````

Aquí tenemos una parte del modelo, hemos hecho *pruning* porque el árbol original tiene (N+1) ramas con una profundidad máxima de `r max_depth_tree_model` y `r length(tree_model$splits)` particiones; con lo que queda claro el motivo por el que recortar el árbol a mostrar.

````{r}
brief_tree_model<-prune.rpart(tree_model,cp=0.01)

fancyRpartPlot(brief_tree_model,caption="Extracto de la totalidad del árbol")
````


### Evaluación del modelo

Ahora hacemos la predicción del precio con el modelo y el conjunto de datos de test.
````{r}
prices_pred<-predict(tree_model,newdata=x_test)
prices_real<-x_test$price.actual
````

Teniendo los valores esperados y reales podemos calcular una de las métricas que identifica la calidad del modelo, el **root mean square error**.

````{r}
rmse_tree_model<-rmse(preds = prices_pred,actuals = prices_real)
````

Podemos ver que el modelo tiene un **root mean square error** de: `r round(rmse_tree_model,3)`, teniendo en cuenta que los valores escalados van entre `r min(x_train$price.actual)` y `r max(x_train$price.actual)` ese valor medio del error no parece demasiado para un módelo con una configuración tan simple.

### Feature importance

Más allá de la calidad del árbol podemos ver las variables más importantes a la hora de hacer la regresión. Esta importancia se estima por la cantidad de divisiones que se han hecho teniendo en cuenta esa variable. Dado que el algoritmo tiene en cuenta la variable y la condición para la que se puede tener una mayor minimización de la entropía, se entiende que la variable elegida es más relevante que el resto. Por ello las variables con mayor frecuencia de uso en las divisiones se les considera como las más importantes en todo el árbol.

````{r}
sum_nodes_tree<-sum(tree_model$variable.importance)
feature_importance_tree_model_percentage<-(100*tree_model$variable.importance/sum_nodes_tree)

````


<p>
  <a class="btn btn-primary" data-toggle="collapse" href="#featureimportance" role="button" aria-expanded="false" aria-controls="featureimportance">
    Tabla con la importancia de cada una de las variables según el árbol de regresión
  </a>
</p>
<div class="collapse" id="featureimportance">
  <div class="card card-body">

````{r}
kable(feature_importance_tree_model_percentage)
````

  </div>
</div>



# Referencias
(1) https://www.kaggle.com/nicholasjhana/energy-consumption-generation-prices-and-weather?select=weather_features.csv
(2) https://data.library.virginia.edu/understanding-q-q-plots/
(3) https://es.wikipedia.org/wiki/Propagaci%C3%B3n_de_errores
(4) http://pages.stat.wisc.edu/~st571-1/06-tables-4.pdf
(5) http://networkianos.com/odd-ratio-que-es-como-se-interpreta/#toc-3 
(6) https://prevencion.umh.es/files/2015/03/riesgo-relativo-y-odds-ratio.pdf
(7) https://stats.stackexchange.com/questions/25839/logistic-regression-in-r-returning-na-values
(8) https://en.wikipedia.org/wiki/Hosmer%E2%80%93Lemeshow_test 
(9) https://www.statisticshowto.com/hosmer-lemeshow-test/ 
(N) http://www.learnbymarketing.com/tutorials/rpart-decision-trees-in-r/ 
(N+1) https://stackoverflow.com/questions/40897081/how-can-i-get-the-depth-of-the-tree-in-rpart-model
(N+2) https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm
(N+3) https://stat.ethz.ch/pipermail/r-help/2007-April/129620.html
(N+4) **Carles Rovira Escofet**. *Teorema del límite central*. UOC
(N+5) https://web.stanford.edu/class/stats300b/Notes/contiguity-and-asymptotics.pdf
(N+6) https://journal.r-project.org/archive/2009/RJ-2009-015/RJ-2009-015.pdf